{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyObAzoBVHLXRl19V/qcHjPm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ioannis-toumpoglou/pytorch-repo/blob/main/04_pytorch_custom_datasets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch Custom Datasets\n",
        "\n",
        "## Domain Libraries\n",
        "\n",
        "Depending on the problem, whether it is vision, text, audio or recommendation, look into each of the PyTorch domain libraries for existing data loading functions and customizable data loading functions."
      ],
      "metadata": {
        "id": "UPaCYgfX6vRh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Importing PyTorch and setting up device-agnostic code"
      ],
      "metadata": {
        "id": "XX5GNF4b7E0L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "# Note: PyTorch 1.10.0 and above is required\n",
        "torch.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "k6ahzH457PNG",
        "outputId": "c5f88d9f-ad3d-4fb2-ea17-906fff3d6f08"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.0.1+cu118'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup device-agnostic device\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "GZsv3S4Z8E26",
        "outputId": "8e324281-508e-4708-8e81-adc7077421ff"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Get data\n",
        "\n",
        "The dataset is a subset of the Food101 dataset.\n",
        "\n",
        "Food101 starts 101 different classes of food and 1000 images per class (750 training, 250 testing)\n",
        "\n",
        "This dataset starts with 3 classes and only 10% of the images (~75 training, 25 testing).\n",
        "\n",
        "\n",
        "Why?\n",
        "\n",
        "\n",
        "When starting a ML project, it is important to try things out on a small scale and then gradually increase the scale, when necessary.\n",
        "\n",
        "The whole point is to speed up how fast you can experiment."
      ],
      "metadata": {
        "id": "D9CfCKk7-m6C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "\n",
        "# Setup a path to a data folder\n",
        "data_path = Path('data/')\n",
        "image_path = data_path / 'pizza_steak_sushi'\n",
        "\n",
        "# If the image folder doesn't exist, download it and prepare it\n",
        "if image_path.is_dir():\n",
        "  print(f'{image_path} directory already exists... Skipping download')\n",
        "else:\n",
        "  print(f'{image_path} directory doesn\\'t exist... Creating directory')\n",
        "  image_path.mkdir(parents=True,\n",
        "                   exist_ok=True)\n",
        "  \n",
        "# Download data\n",
        "with open(data_path / 'pizza_steak_sushi.zip', 'wb') as file:\n",
        "  request = requests.get(url='https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip')\n",
        "  print(f'Downloading the dataset...')\n",
        "  file.write(request.content)\n",
        "\n",
        "# Unzip the downloaded file\n",
        "with zipfile.ZipFile(data_path / 'pizza_steak_sushi.zip', 'r') as zip_ref:\n",
        "  print('Unzipping the dataset file...')\n",
        "  zip_ref.extractall(image_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMlTl-OL-vV8",
        "outputId": "6a089f38-5b4c-4752-f6d0-a18ddeb2bf7e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data/pizza_steak_sushi directory already exists... Skipping download\n",
            "Downloading the dataset...\n",
            "Unzipping the dataset file...\n"
          ]
        }
      ]
    }
  ]
}